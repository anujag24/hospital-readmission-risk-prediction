{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict all cause 30-day hospital readmission risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libs into the python environment. These functions will be referenced later in the notebook code.\n",
    "\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# Put this when it's called\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "\n",
    "# Create table for missing data analysis\n",
    "def draw_missing_data_table(df):\n",
    "    total = df.isnull().sum().sort_values(ascending=False)\n",
    "    percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)\n",
    "    missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "    return missing_data*100\n",
    "\n",
    "# Plot learning curve\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Validation score\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "\n",
    "# Plot validation curve\n",
    "def plot_validation_curve(estimator, title, X, y, param_name, param_range, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    train_scores, test_scores = validation_curve(estimator, X, y, param_name, param_range, cv)\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    train_std = np.std(train_scores, axis=1)\n",
    "    test_mean = np.mean(test_scores, axis=1)\n",
    "    test_std = np.std(test_scores, axis=1)\n",
    "    plt.plot(param_range, train_mean, color='r', marker='o', markersize=5, label='Training score')\n",
    "    plt.fill_between(param_range, train_mean + train_std, train_mean - train_std, alpha=0.15, color='r')\n",
    "    plt.plot(param_range, test_mean, color='g', linestyle='--', marker='s', markersize=5, label='Validation score')\n",
    "    plt.fill_between(param_range, test_mean + test_std, test_mean - test_std, alpha=0.15, color='g')\n",
    "    plt.grid() \n",
    "    plt.xscale('log')\n",
    "    plt.legend(loc='best') \n",
    "    plt.xlabel('Parameter') \n",
    "    plt.ylabel('Score') \n",
    "    plt.ylim(ylim)\n",
    "    \n",
    "## Plot Precision Recall threshold curve  \n",
    "def precision_recall_threshold(p, r, thresholds, t=0.5):\n",
    "    \"\"\"\n",
    "    plots the precision recall curve and shows the current value for each\n",
    "    by identifying the classifier's threshold (t).\n",
    "    \"\"\"\n",
    "    \n",
    "    # generate new class predictions based on the adjusted_classes\n",
    "    # function above and view the resulting confusion matrix.\n",
    "    y_pred_adj = adjusted_classes(y_scores, t)\n",
    "    print(pd.DataFrame(confusion_matrix(y_test, y_pred_adj),\n",
    "                       columns=['pred_neg', 'pred_pos'], \n",
    "                       index=['neg', 'pos']))\n",
    "    \n",
    "    # plot the curve\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.title(\"Precision and Recall curve ^ = current threshold\")\n",
    "    plt.step(r, p, color='b', alpha=0.2,\n",
    "             where='post')\n",
    "    plt.fill_between(r, p, step='post', alpha=0.2,\n",
    "                     color='b')\n",
    "    plt.ylim([0.5, 1.01]);\n",
    "    plt.xlim([0.5, 1.01]);\n",
    "    plt.xlabel('Recall');\n",
    "    plt.ylabel('Precision');\n",
    "    \n",
    "    # plot the current threshold on the line\n",
    "    close_default_clf = np.argmin(np.abs(thresholds - t))\n",
    "    plt.plot(r[close_default_clf], p[close_default_clf], '^', c='k',\n",
    "            markersize=15)\n",
    "\n",
    "## plot_precision_recall_vs_threshold\n",
    "    def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.title(\"Precision and Recall Scores as a function of the decision threshold\")\n",
    "        plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n",
    "        plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")\n",
    "        plt.ylabel(\"Score\")\n",
    "        plt.xlabel(\"Decision Threshold\")\n",
    "        plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thinking about Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to understand the relationship between different tables and the data in those tables. This is important to identify the information which is relevant to the prediction. Here is the schema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and Visualizing Your Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"EHR.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import botocore \n",
    "bucket = 'readmission-data-ehr' # Update this to the bucket that was created in your lab account as part of this enviroment.\n",
    "train_prefix = \"train-data/2020/2/20\"\n",
    "validation_predix = \"vat\"-data/2020/2/20\"\n",
    " \n",
    "s3 = boto3.resource('s3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing using Apache Spark in AWS Glue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and run AWS Glue Preprocessing Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll be creating Glue client via Boto so that we can invoke the create_job API of Glue. create_job API will create a job definition which can be used to execute your jobs in Glue. The job definition created here is mutable. While creating the job, we are also passing the code location as well as the dependencies location to Glue.\n",
    "\n",
    "The job will be executed by calling start_job_run API. This API creates an immutable run/execution corresponding to the job definition created above. We will require the job_run_id for the particular job execution to check for status. We'll pass the data and model locations as part of the job execution parameters.\n",
    "\n",
    "Finally we will check for the job status to see if it has succeeded, failed or stopped. Once the job is succeeded, we have the transformed data into S3 in CSV format which we can use with XGBoost for training. If the job fails, you can go to AWS Glue console, click on Jobs tab on the left, and from the page, click on this particular job and you will be able to find the CloudWatch logs (the link under Logs) link for these jobs which can help you to see what exactly went wrong in the job execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job already exists, continuing...\n",
      "{'JobRunId': 'jr_fc0cf326cb1e63b55b5d17987156df62a92a4d0e92eb483bde002d891050f3bf', 'ResponseMetadata': {'RequestId': '31bd168e-d76b-4e5f-961a-6fb4373237eb', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Wed, 19 Feb 2020 23:20:48 GMT', 'content-type': 'application/x-amz-json-1.1', 'content-length': '82', 'connection': 'keep-alive', 'x-amzn-requestid': '31bd168e-d76b-4e5f-961a-6fb4373237eb'}, 'RetryAttempts': 0}}\n",
      "\n",
      "RUNNING\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-360334b64849>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mjob_run_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_job_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJobName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mRunId\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_run_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'JobRun'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'JobRunState'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mjob_run_status\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Create and run AWS Glue Preprocessing Job\n",
    "\n",
    "# Define the Job in AWS Glue\n",
    "glue = boto3.client('glue')\n",
    "\n",
    "try:\n",
    "    glue.get_job(JobName='glue-etl-produce-traing-data')\n",
    "    print(\"Job already exists, continuing...\")\n",
    "except glue.exceptions.EntityNotFoundException:\n",
    "    print('{}\\n'.format(\"Job Not Found, Check the output of Cloud Formation template\"))\n",
    "\n",
    "# Run the job in AWS Glue\n",
    "try:\n",
    "    job_name='glue-etl-produce-traing-data'\n",
    "    response = glue.start_job_run(JobName=job_name)\n",
    "    job_run_id = response['JobRunId']\n",
    "    print('{}\\n'.format(response))\n",
    "except glue.exceptions.ConcurrentRunsExceededException:\n",
    "    print(\"Job run already in progress, continuing...\")\n",
    "\n",
    "    \n",
    "# Check on the job status\n",
    "import time\n",
    "\n",
    "job_run_status = glue.get_job_run(JobName=job_name,RunId=job_run_id)['JobRun']['JobRunState']\n",
    "while job_run_status not in ('FAILED', 'SUCCEEDED', 'STOPPED'):\n",
    "    job_run_status = glue.get_job_run(JobName=job_name,RunId=job_run_id)['JobRun']['JobRunState']\n",
    "    print (job_run_status)\n",
    "    time.sleep(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "import pyarrow.parquet as pq\n",
    "from pyarrow.filesystem import S3FSWrapper\n",
    "\n",
    "fs = s3fs.S3FileSystem()\n",
    "\n",
    "\n",
    "# Python 3.6 or later\n",
    "p_dataset = pq.ParquetDataset(\n",
    "    f\"s3://{bucket}/{prefix}\",\n",
    "    filesystem=fs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>readmission</th>\n",
       "      <th>features_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>(322,[1,4,5,7,8,12,13,112,144,314,315,316,318,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>(322,[1,4,5,7,8,12,13,112,144,314,315,316,318,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>(322,[1,4,5,7,8,12,13,112,144,314,315,316,318,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>(322,[1,4,5,7,8,13,112,144,314,315,316,318,320...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>(322,[1,4,5,7,8,12,13,112,144,314,315,316,318,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   readmission                                       features_str\n",
       "0            0  (322,[1,4,5,7,8,12,13,112,144,314,315,316,318,...\n",
       "1            0  (322,[1,4,5,7,8,12,13,112,144,314,315,316,318,...\n",
       "2            0  (322,[1,4,5,7,8,12,13,112,144,314,315,316,318,...\n",
       "3            0  (322,[1,4,5,7,8,13,112,144,314,315,316,318,320...\n",
       "4            0  (322,[1,4,5,7,8,12,13,112,144,314,315,316,318,..."
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ft_select_category = p_dataset.read().to_pandas()\n",
    "\n",
    "df_ft_select_category.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4654082 entries, 0 to 4654081\n",
      "Data columns (total 2 columns):\n",
      "readmission     int32\n",
      "features_str    object\n",
      "dtypes: int32(1), object(1)\n",
      "memory usage: 53.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_ft_select_category.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    (322,[1,4,5,7,8,12,13,112,144,314,315,316,318,...\n",
       "1    (322,[1,4,5,7,8,12,13,112,144,314,315,316,318,...\n",
       "2    (322,[1,4,5,7,8,12,13,112,144,314,315,316,318,...\n",
       "3    (322,[1,4,5,7,8,13,112,144,314,315,316,318,320...\n",
       "4    (322,[1,4,5,7,8,12,13,112,144,314,315,316,318,...\n",
       "Name: features_str, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "df_ft_select_category[\"features_str\"].head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SparseVector' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-432f5472e6d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_ft_select_category\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_ft_select_category\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"features_str\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSparseVector\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'SparseVector' is not defined"
     ]
    }
   ],
   "source": [
    "df_ft_select_category = df_ft_select_category.astype({\"features_str\": SparseVector})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map(lambda x : x,df_ft_select_category[\"features_str\"].iloc[0:1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot Confusion Matrix function\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.savefig(\"confusionmatrix.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# end Confusion Matrix function\n",
    "\n",
    "\n",
    "# ROC Curve Plotting function\n",
    "\n",
    "def plot_roc_curve(fpr,tpr):\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b',\n",
    "             label='AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot([0, 1], [0, 1], 'r--')\n",
    "    plt.xlim([-0.1, 1.2])\n",
    "    plt.ylim([-0.1, 1.2])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "#end ROC plotting function\n",
    "\n",
    "\n",
    "# Precision Recall (PR) function\n",
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\", linewidth=2)\n",
    "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\", linewidth=2)\n",
    "    plt.xlabel(\"Threshold\", fontsize=16)\n",
    "    plt.legend(loc=\"upper left\", fontsize=16)\n",
    "    plt.ylim([0, 1])\n",
    "    plt.show( )\n",
    "    plt.close()\n",
    "\n",
    "#end PR function\n",
    "\n",
    "## Grid Search Wrapper function\n",
    "def grid_search_wrapper(refit_score='precision_score'):\n",
    "    \"\"\"\n",
    "    fits a GridSearchCV classifier using refit_score for optimization\n",
    "    prints classifier performance metrics\n",
    "    \"\"\"\n",
    "    skf = StratifiedKFold(n_splits=10)\n",
    "    grid_search = GridSearchCV(clf, param_grid, scoring=scorers, refit=refit_score,\n",
    "                           cv=skf, return_train_score=True, n_jobs=-1)\n",
    "    grid_search.fit(X_train.values, y_train.values)\n",
    "\n",
    "    # make the predictions\n",
    "    y_pred = grid_search.predict(X_test.values)\n",
    "\n",
    "    print('Best params for {}'.format(refit_score))\n",
    "    print(grid_search.best_params_)\n",
    "\n",
    "    # confusion matrix on the test data.\n",
    "    print('\\nConfusion matrix of Random Forest optimized for {} on the test data:'.format(refit_score))\n",
    "    print(pd.DataFrame(confusion_matrix(y_test, y_pred),\n",
    "                 columns=['pred_neg', 'pred_pos'], index=['neg', 'pos']))\n",
    "    return grid_search\n",
    "## End Grid Search wrapper function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train class distribution\n",
      "0    0.933209\n",
      "1    0.066791\n",
      "Name: readmission, dtype: float64\n",
      "y_test class distribution\n",
      "0    0.932854\n",
      "1    0.067146\n",
      "Name: readmission, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X_train = df_ft_select_category[df_ft_select_category.columns.difference(['readmission'])]\n",
    "Y_train = df_ft_select_category['readmission']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.30, random_state=0)\n",
    "\n",
    "\n",
    "# show the train and test distribution\n",
    "print('y_train class distribution')\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print('y_test class distribution')\n",
    "print(y_test.value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test prevalence(n = 698112): 0.06662111523652366\n",
      "Valid prevalence(n = 698113): 0.06698342531939672\n",
      "Train all prevalence(n = 3257857): 0.06693848133911341\n",
      "all samples (n = 4654082)\n"
     ]
    }
   ],
   "source": [
    "## Sampling data for balanced positives and negatives\n",
    "# shuffle the samples\n",
    "df_ft_select_category = df_ft_select_category.sample(n = len(df_ft_select_category), random_state = 42)\n",
    "df_ft_select_category = df_ft_select_category.reset_index(drop = True)\n",
    "\n",
    "# Save 30% of the data as validation and test data \n",
    "df_valid_test=df_ft_select_category.sample(frac=0.30,random_state=42)\n",
    "\n",
    "df_test = df_valid_test.sample(frac = 0.5, random_state = 42)\n",
    "df_valid = df_valid_test.drop(df_test.index)\n",
    "\n",
    "# use the rest of the data as training data\n",
    "df_train_all=df_ft_select_category.drop(df_valid_test.index)\n",
    "\n",
    "print('Test prevalence(n = %d):'%len(df_test),df_test.readmission.sum()/ len(df_test))\n",
    "print('Valid prevalence(n = %d):'%len(df_valid),df_valid.readmission.sum()/ len(df_valid))\n",
    "print('Train all prevalence(n = %d):'%len(df_train_all), df_train_all.readmission.sum()/ len(df_train_all))\n",
    "print('all samples (n = %d)'%len(df_ft_select_category))\n",
    "assert len(df_ft_select_category) == (len(df_test)+len(df_valid)+len(df_train_all)),'math didnt work'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train prevalence (n = 436152): 0.5\n"
     ]
    }
   ],
   "source": [
    "# split the training data into positive and negative\n",
    "rows_pos = df_train_all.readmission == 1\n",
    "df_train_pos = df_train_all.loc[rows_pos]\n",
    "df_train_neg = df_train_all.loc[~rows_pos]\n",
    "\n",
    "# merge the balanced data\n",
    "df_train = pd.concat([df_train_pos, df_train_neg.sample(n = len(df_train_pos), random_state = 42)],axis = 0)\n",
    "\n",
    "# shuffle the order of training samples \n",
    "df_train = df_train.sample(n = len(df_train), random_state = 42).reset_index(drop = True)\n",
    "\n",
    "\n",
    "print('Train prevalence (n = %d):'%len(df_train), df_train.readmission.sum()/ len(df_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'MA'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-38d9d1cf2c8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m logisticRegr = LogisticRegression(random_state=0, solver='lbfgs',\n\u001b[1;32m      9\u001b[0m multi_class='multinomial', max_iter=1000)\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mlogisticRegr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0my_test_pred_LR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogisticRegr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogisticRegr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[0;32m-> 1532\u001b[0;31m                          accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[1;32m   1533\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    720\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'MA'"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Model\n",
    "\n",
    "## Since number of negatives samples are higher than positive samples so balancing the data \n",
    "Y_train = df_train['readmission']\n",
    "X_train = df_train[df_train.columns.difference(['readmission'])]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.30, random_state=0)\n",
    "\n",
    "logisticRegr = LogisticRegression(random_state=0, solver='lbfgs',\n",
    "multi_class='multinomial', max_iter=1000)\n",
    "logisticRegr.fit(x_train, y_train)\n",
    "y_test_pred_LR = cross_val_predict(logisticRegr, x_test, y_test, cv=3)\n",
    "score = logisticRegr.score(x_test, y_test)\n",
    "y_test_pred = y_test_pred_LR\n",
    "print(\"LR Accuracy\",accuracy_score(y_test, y_test_pred))\n",
    "roc = roc_auc_score(y_test, y_test_pred)\n",
    "print(\"roc score\", roc)\n",
    "print(\"Classification Report\")\n",
    "print(\"=\"*50)\n",
    "LR_CR = classification_report(y_test, y_test_pred)\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "# Plot   confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "plot_confusion_matrix(cnf_matrix, classes=['Class 0', 'Class 1'],\n",
    "  title='Confusion matrix, without normalization')\n",
    "    \n",
    "# Compute ROC curve and ROC area\n",
    "#fpr, tpr, thrsehold = roc_curve(y_test , y_test_pred)\n",
    "  \n",
    "\n",
    "    \n",
    "logit_roc_auc = roc_auc_score(y_test_pred, logisticRegr.predict(x_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, logisticRegr.predict_proba(x_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression ' ) \n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    " \n",
    "plt.show()\n",
    "\n",
    "\n",
    "title = \"Learning Curves (Logistic Regression)\"\n",
    "# Cross validation with 5 iterations to get smoother mean test and train\n",
    "# score curves, each time with 20% data randomly selected as a validation set.\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "estimator = LogisticRegression( C = 0.0001, penalty = 'l2')\n",
    "plot_learning_curve(estimator, title, x_train, y_train, ylim=(0.2, 1.01), cv=cv, n_jobs=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Model\n",
    "\n",
    "sgd_clf = SGDClassifier(random_state=0, loss=\"log\", max_iter=1000, tol=3 )\n",
    "sgd_clf.fit(x_train, y_train)\n",
    "cross_val_score(sgd_clf, x_train, y_train, cv=3, scoring=\"accuracy\")\n",
    "y_test_pred_SVC = cross_val_predict(sgd_clf, x_test, y_test, cv=3)\n",
    "predictions = sgd_clf.predict(x_test)\n",
    "score = sgd_clf.score(x_test, y_test)\n",
    "y_test_pred = y_test_pred_SVC\n",
    "print(\"SVM Accuracy\",accuracy_score(y_test, y_test_pred))\n",
    "roc = roc_auc_score(y_test, y_test_pred_SVC)\n",
    "print(\"roc score\", roc)\n",
    "SVM_CR = classification_report(y_test, y_test_pred)\n",
    "print(\"Classification Report\")\n",
    "print(\"=\"*50)\n",
    "print(SVM_CR)\n",
    "# Plot   confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "plot_confusion_matrix(cnf_matrix, classes=['Class 0', 'Class 1'],\n",
    "  title='Confusion matrix, without normalization')\n",
    "    \n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr, tpr, thrsehold = roc_curve(y_test , y_test_pred)\n",
    "  \n",
    "    \n",
    "roc_auc = roc_auc_score(y_test_pred, sgd_clf.predict(x_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, sgd_clf.predict_proba(x_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='SVM  ' ) \n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "precision_recall_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## XGBoost - Sagemaker Native \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '[0.0,1.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2029461.7100000002,344377.8399999999,129.16,89.16,129.16,0.0,95999.0,106.5068493150685]'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-7f1b2cbd4070>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mRF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mRF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0my_test_pred_RF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    726\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'M8[ns]'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array_wrap__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pandas/core/arrays/numpy_.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0m_HANDLED_TYPES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '[0.0,1.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2029461.7100000002,344377.8399999999,129.16,89.16,129.16,0.0,95999.0,106.5068493150685]'"
     ]
    }
   ],
   "source": [
    "# Random Forest Model with original sampling data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "RF.fit(x_train.features_str, y_train)\n",
    "cross_val_score(RF, x_train, y_train, cv=3, scoring=\"accuracy\")\n",
    "y_test_pred_RF = cross_val_predict(RF, x_test, y_test, cv=3)\n",
    "predictions = RF.predict(x_test)\n",
    "score = RF.score(x_test, y_test)\n",
    "y_test_pred = y_test_pred_RF\n",
    "print(\"RF Accuracy\",accuracy_score(y_test, y_test_pred))\n",
    "roc = roc_auc_score(y_test, y_test_pred)\n",
    "print(\"roc score\", roc)\n",
    "RF_CR = classification_report(y_test, y_test_pred)\n",
    "print(\"Classification Report\")\n",
    "print(\"=\"*50)\n",
    "print(RF_CR)\n",
    "# Plot   confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "plot_confusion_matrix(cnf_matrix, classes=['Class 0', 'Class 1'],\n",
    "                      title='Confusion matrix, without normalization')\n",
    "    \n",
    "    \n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr, tpr, thrsehold = roc_curve(y_test , y_test_pred)\n",
    " \n",
    "roc_auc = roc_auc_score(y_test_pred, RF.predict(x_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, RF.predict_proba(x_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Random Forest ' )\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(\"randonforest-roc-auc-curve.png\")\n",
    "plt.show()\n",
    "\n",
    "## Precision Recall Curve \n",
    "y_score_rf = RF.predict_proba(x_test)[:,-1]\n",
    "average_precision = average_precision_score(y_test, y_score_rf)\n",
    "print('Average precision-recall score RF: {}'.format(average_precision))\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score_rf)\n",
    "\n",
    "plt.step(recall, precision, color='b', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.2,\n",
    "                 color='b')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(\n",
    "          average_precision))\n",
    "plt.show()\n",
    "\n",
    "# decision thresholds plot\n",
    "plot_precision_recall_vs_threshold(precision, recall, thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random Forest Model with overfitting data\n",
    "## This is giving incorrect results. It's predicting that certain procedures require readmission but when validated \n",
    "## with the data, it was not the case. For example \n",
    "\n",
    "X_train = df_train[df_train.columns.difference(['readmission'])]\n",
    "Y_train = df_train['readmission']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.30, random_state=0)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF = RandomForestClassifier(random_state=42, n_estimators=20)\n",
    "RF.fit(x_train, y_train)\n",
    "cross_val_score(RF, x_train, y_train, cv=3, scoring=\"accuracy\")\n",
    "y_test_pred_RF = cross_val_predict(RF, x_test, y_test, cv=3)\n",
    "predictions = RF.predict(x_test)\n",
    "score = RF.score(x_test, y_test)\n",
    "y_test_pred = y_test_pred_RF\n",
    "print(\"RF Accuracy\",accuracy_score(y_test, y_test_pred))\n",
    "roc = roc_auc_score(y_test, y_test_pred)\n",
    "print(\"roc score\", roc)\n",
    "RF_CR = classification_report(y_test, y_test_pred)\n",
    "print(\"Classification Report\")\n",
    "print(\"=\"*50)\n",
    "print(RF_CR)\n",
    "# Plot   confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "plot_confusion_matrix(cnf_matrix, classes=['Class 0', 'Class 1'],\n",
    "                      title='Confusion matrix, without normalization')\n",
    "    \n",
    "    \n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr, tpr, thrsehold = roc_curve(y_test , y_test_pred)\n",
    " \n",
    "roc_auc = roc_auc_score(y_test_pred, RF.predict(x_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, RF.predict_proba(x_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Random Forest ' )\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(\"randonforest-roc-auc-curve.png\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "## Precision Recall Curve \n",
    "y_score_rf = RF.predict_proba(x_test)[:,-1]\n",
    "average_precision = average_precision_score(y_test, y_score_rf)\n",
    "print('Average precision-recall score RF: {}'.format(average_precision))\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score_rf)\n",
    "\n",
    "plt.step(recall, precision, color='b', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.2,\n",
    "                 color='b')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(\n",
    "          average_precision))\n",
    "plt.show()\n",
    "\n",
    "# decision thresholds plot\n",
    "plot_precision_recall_vs_threshold(precision, recall, thresholds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Multi-Layer Perceptron (NN) classification\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(20, 20, 20), max_iter=1000)\n",
    "mlp.fit(x_test, y_test)\n",
    "\n",
    "cross_val_score(mlp, x_train, y_train, cv=3, scoring=\"accuracy\")\n",
    "\n",
    "y_test_pred_NN = cross_val_predict(mlp, x_test, y_test, cv=3)\n",
    "predictions = mlp.predict(x_test)\n",
    "score = mlp.score(x_test, y_test)\n",
    "\n",
    "y_test_pred = y_test_pred_NN\n",
    "print(\"NN Accuracy\",accuracy_score(y_test, y_test_pred))\n",
    "roc = roc_auc_score(y_test, y_test_pred)\n",
    "print(\"roc score\", roc)\n",
    "NN_CR = classification_report(y_test, y_test_pred)\n",
    "print(\"Classification Report\")\n",
    "print(\"=\"*50)\n",
    "print(NN_CR)\n",
    "    \n",
    "# Plot   confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "plot_confusion_matrix(cnf_matrix, classes=['Class 0', 'Class 1'],\n",
    "  title='Confusion matrix, without normalization') \n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr, tpr, thrsehold = roc_curve(y_test , y_test_pred)\n",
    "roc_auc  = auc(fpr , tpr )\n",
    "  \n",
    " \n",
    "    \n",
    "     \n",
    "roc_auc = roc_auc_score(y_test_pred, mlp.predict(x_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, mlp.predict_proba(x_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='MLP  '  )\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GradientBoostingClassifier\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=20, learning_rate=0.5, max_features=2, max_depth=2, random_state=0)\n",
    "gb_clf.fit(x_train, y_train)\n",
    "\n",
    "cross_val_score(gb_clf, x_train, y_train, cv=3, scoring=\"accuracy\")\n",
    "y_test_pred_gb = cross_val_predict(gb_clf, x_test, y_test, cv=3)\n",
    "predictions = gb_clf.predict(x_test)\n",
    "score = gb_clf.score(x_test, y_test)\n",
    "y_test_pred = y_test_pred_gb\n",
    "print(\"GB Accuracy\",accuracy_score(y_test, y_test_pred))\n",
    "roc = roc_auc_score(y_test, y_test_pred)\n",
    "print(\"roc score\", roc)\n",
    "GB_CR = classification_report(y_test, y_test_pred)\n",
    "print(\"Classification Report\")\n",
    "print(\"=\"*50)\n",
    "print(GB_CR)\n",
    "    \n",
    "# Plot   confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "plot_confusion_matrix(cnf_matrix, classes=['Class 0', 'Class 1'],\n",
    "  title='Confusion matrix, without normalization')\n",
    "  \n",
    "    \n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr, tpr, thrsehold = roc_curve(y_test , y_test_pred)\n",
    "roc_auc  = auc(fpr , tpr )\n",
    " \n",
    " \n",
    "roc_auc = roc_auc_score(y_test_pred, gb_clf.predict(x_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, gb_clf.predict_proba(x_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Gradient Boosting  '  )\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "     \n",
    "plt.show()\n",
    "\n",
    "## Precision Recall Curve \n",
    "y_score_rf = gb_clf.predict_proba(x_test)[:,-1]\n",
    "average_precision = average_precision_score(y_test, y_score_rf)\n",
    "print('Average precision-recall score RF: {}'.format(average_precision))\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_score_rf)\n",
    "\n",
    "plt.step(recall, precision, color='b', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.2,\n",
    "                 color='b')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(\n",
    "          average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Model\n",
    "DT = DecisionTreeClassifier(random_state=42)\n",
    "DT.fit(x_train, y_train)\n",
    "cross_val_score(DT, x_train, y_train, cv=3, scoring=\"accuracy\")\n",
    "y_test_pred_DT = cross_val_predict(DT, x_test, y_test, cv=3)\n",
    "predictions = DT.predict(x_test)\n",
    "score = DT.score(x_test, y_test)\n",
    "y_test_pred = y_test_pred_DT\n",
    "print(\"DT Accuracy\",accuracy_score(y_test, y_test_pred))\n",
    "roc = roc_auc_score(y_test, y_test_pred)\n",
    "print(\"roc score\", roc)\n",
    "DT_CR = classification_report(y_test, y_test_pred)\n",
    "print(\"Classification Report\")\n",
    "print(\"=\"*50)\n",
    "print(DT_CR)\n",
    "# Plot   confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "plot_confusion_matrix(cnf_matrix, classes=['Class 0', 'Class 1'],\n",
    "  title='Confusion matrix, without normalization')\n",
    "    \n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr, tpr, thrsehold = roc_curve(y_test , y_test_pred)\n",
    " \n",
    "    \n",
    "roc_auc = roc_auc_score(y_test_pred, DT.predict(x_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, DT.predict_proba(x_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Decision Tree '  )\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "     \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## After analysis of the different models, it is found that Randon Forest Model fits best on the current data set \n",
    "## As a next step, Identifying the significant features in the model\n",
    "feature_list = list(x_train.columns)\n",
    "\n",
    "\n",
    "# Get numerical feature importances\n",
    "importances = list(RF.feature_importances_)\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of tuples with variable and importance\n",
    "for pair in feature_importances:\n",
    "    if pair[1] > 0:\n",
    "        print (pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "with open('significant_features.csv', 'w') as feature_file:\n",
    "    file_writer = csv.writer(feature_file)\n",
    "    item_length = len(feature_importances[0])\n",
    "    file_writer.writerow(['significant_feature','importance'])\n",
    "    for pair in feature_importances:\n",
    "        if pair[1] > 0:\n",
    "            print (pair)\n",
    "            file_writer.writerow(pair)\n",
    "s3.Bucket(bucket).upload_file('significant_features.csv','processed-data/significant_features.csv',ExtraArgs={\"ServerSideEncryption\": \"aws:kms\",\"SSEKMSKeyId\":\"3a90a5d2-2ba8-4942-b9df-9a27ff7bf412\" })\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameter tuning of Random Forest Model\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# number of features at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# max depth\n",
    "max_depth = [int(x) for x in np.linspace(100, 500, num = 11)]\n",
    "max_depth.append(None)\n",
    "# create random grid\n",
    "random_grid = {\n",
    " 'n_estimators': n_estimators,\n",
    " 'max_features': max_features,\n",
    " 'max_depth': max_depth\n",
    " }\n",
    "# Random search of parameters\n",
    "rfc_random = RandomizedSearchCV(estimator = RF, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the model\n",
    "rfc_random.fit(x_train, y_train)\n",
    "# print results\n",
    "print(rfc_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.Bucket(bucket).download_file('batch-transform/processed-data/readmission-predict-input-data.pkl', 'readmission-predict-input-data.pkl')\n",
    "x_test_temp = pickle.load(open('readmission-predict-input-data.pkl', 'rb'))\n",
    "x_test_temp.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_difference = X_train - x_test_temp\n",
    "feature_difference_df = pd.DataFrame(data=np.zeros((x_test_temp.shape[0], len(feature_difference))),\n",
    "                                     columns=list(feature_difference))\n",
    "# add \"missing\" features back to `test\n",
    "x_test_temp = x_test_temp.join(feature_difference_df)\n",
    "\n",
    "#x_test_temp.info()\n",
    "feature_difference_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dropping the features which are present in test but not in training data  \n",
    "feature_difference = set(x_test_temp.columns).difference(set(X_train.columns))\n",
    "for feature in feature_difference:\n",
    "    print (feature)\n",
    "\n",
    "x_test_temp2 = x_test_temp.drop(columns=feature_difference)\n",
    "x_test_temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_temp = RF.predict(x_test_temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_temp_df = pd.DataFrame(predictions_temp)\n",
    "predictions_temp_df = predictions_temp_df.rename(columns={0: \"readmission\"})\n",
    "predictions_temp_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##df_first_merge = pd_read_s3_multiple_parquets(prefix, bucket)\n",
    "import boto3\n",
    "import botocore \n",
    "import io\n",
    "bucket = 'readmission-data' # Update this to the bucket that was created in your lab account as part of this enviroment.\n",
    "prefix = \"batch-transform/output\"\n",
    " \n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "import s3fs\n",
    "import pyarrow.parquet as pq\n",
    "from pyarrow.filesystem import S3FSWrapper\n",
    "\n",
    "fs = s3fs.S3FileSystem()\n",
    "\n",
    "\n",
    "# Python 3.6 or later\n",
    "p_dataset = pq.ParquetDataset(\n",
    "    f\"s3://{bucket}/{prefix}\",\n",
    "    filesystem=fs\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowInvalid",
     "evalue": "Mix of struct and list types not yet supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-fc690c0bf4fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pyarrow/parquet.py\u001b[0m in \u001b[0;36mread_pandas\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1163\u001b[0m             \u001b[0mContent\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtable\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mof\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \"\"\"\n\u001b[0;32m-> 1165\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_pandas_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_common_pandas_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pyarrow/parquet.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, columns, use_threads, use_pandas_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m             table = piece.read(columns=columns, use_threads=use_threads,\n\u001b[1;32m   1136\u001b[0m                                \u001b[0mpartitions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartitions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1137\u001b[0;31m                                use_pandas_metadata=use_pandas_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m             \u001b[0mtables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pyarrow/parquet.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, columns, use_threads, partitions, file, use_pandas_metadata)\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_row_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m             \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition_keys\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pyarrow/parquet.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, columns, use_threads, use_pandas_metadata)\u001b[0m\n\u001b[1;32m    251\u001b[0m             columns, use_pandas_metadata=use_pandas_metadata)\n\u001b[1;32m    252\u001b[0m         return self.reader.read_all(column_indices=column_indices,\n\u001b[0;32m--> 253\u001b[0;31m                                     use_threads=use_threads)\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscan_contents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m65536\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pyarrow/_parquet.pyx\u001b[0m in \u001b[0;36mpyarrow._parquet.ParquetReader.read_all\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowInvalid\u001b[0m: Mix of struct and list types not yet supported"
     ]
    }
   ],
   "source": [
    "df = p_dataset.read_pandas()\n",
    "schema = pq.Schema.from_pandas(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_test_df = p_dataset.read().to_pandas()\n",
    "\n",
    "original_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_data = original_test_df[['patient_id','encounters_id','encounters_code','procedures_code','patient_gender','patient_ethnicity','organizations_id']]\n",
    "prediction_data_combine = pd.concat([prediction_data, predictions_temp_df], axis=1)\n",
    "prediction_data_combine.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find out high risk patients\n",
    "high_risk_patient = prediction_data_combine[prediction_data_combine['readmission'] == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_risk_patient_csv = high_risk_patient.to_csv(index=False,header=True)\n",
    "with open('preditions.csv', 'w') as prediction_file:\n",
    "    prediction_file.write(high_risk_patient_csv)\n",
    "prediction_file.close()\n",
    "s3.Bucket(bucket).upload_file('preditions.csv','batch-transform/prediction/preditions.csv',ExtraArgs={\"ServerSideEncryption\": \"aws:kms\",\"SSEKMSKeyId\":\"3a90a5d2-2ba8-4942-b9df-9a27ff7bf412\" })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding entries to Dynamodb for patients\n",
    "import boto3\n",
    "from datetime import datetime\n",
    "dateTimeObj = datetime.now()\n",
    "table = boto3.resource('dynamodb').Table('readmission-prediction')\n",
    "patients = high_risk_patient['patient_id']\n",
    "for patient in patients: \n",
    "    response = table.update_item(\n",
    "        Key={\n",
    "            \"patient_id\" : patient,\n",
    "        },\n",
    "        UpdateExpression='SET readmission = :val1',\n",
    "        ExpressionAttributeValues={\n",
    "            ':val1': 'Y'\n",
    "        }\n",
    "    )\n",
    "    print (response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
