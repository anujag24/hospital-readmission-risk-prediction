{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>26</td><td>application_1581910656831_0027</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-32-37-27.us-west-2.compute.internal:20888/proxy/application_1581910656831_0027/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-32-43-153.us-west-2.compute.internal:8042/node/containerlogs/container_1581910656831_0027_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using SageMaker Spark Integration to train and deploy models on SageMaker using Spark Data Frame for handling very large data sets\n",
    "%pip install sagemaker_pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the necessary modules and create the SparkSession with the SageMaker-Spark dependencies attached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import sagemaker_pyspark\n",
    "\n",
    "# Configure Spark to use the SageMaker Spark dependency jars\n",
    "jars = sagemaker_pyspark.classpath_jars()\n",
    "\n",
    "classpath = \":\".join(sagemaker_pyspark.classpath_jars())\n",
    "\n",
    "# See the SageMaker Spark Github repo under sagemaker-pyspark-sdk\n",
    "# to learn how to connect to a remote EMR cluster running Spark from a Notebook Instance.\n",
    "spark = SparkSession.builder.config(\"spark.driver.extraClassPath\", classpath).getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize a spark session and add sagemaker jars \n",
    "import sagemaker_pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "from sagemaker_pyspark import IAMRole, classpath_jars\n",
    "\n",
    "classpath = \":\".join(sagemaker_pyspark.classpath_jars())\n",
    "spark = SparkSession.builder.config(\"spark.driver.extraClassPath\", classpath).getOrCreate()\n",
    "\n",
    "# Load the sagemaker_pyspark classpath. If you used --jars to submit your job\n",
    "# there is no need to do this in code.\n",
    "#conf = (SparkConf()\n",
    "#        .set(\"spark.driver.extraClassPath\", \":\".join(classpath_jars())))\n",
    "#SparkContext(conf=conf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>26</td><td>application_1581910656831_0027</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-32-37-27.us-west-2.compute.internal:20888/proxy/application_1581910656831_0027/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-32-43-153.us-west-2.compute.internal:8042/node/containerlogs/container_1581910656831_0027_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "## Converting Data Frame to Dynamic Frame and writing to S3\n",
    "today = datetime.datetime.today()\n",
    "year = today.year\n",
    "#month = today.month\n",
    "month = 2\n",
    "#day = today.day\n",
    "day = 25\n",
    "\n",
    "## Read the training data \n",
    "s3_train_bucket = \"readmission-data-ehr\"\n",
    "s3_train_bucket_prefix = \"train-data\"\n",
    "\n",
    "training_data = spark.read.format(\"parquet\").load('s3://'+s3_train_bucket+'/'+s3_train_bucket_prefix+'/'+str(year)+'/'+str(month)+'/'+str(day)+'/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- readmission: integer (nullable = true)"
     ]
    }
   ],
   "source": [
    "training_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Renaming the column as SageMaker XGBoost Algorithm is expecting features and label columns\n",
    "training_data = training_data.withColumnRenamed(\"readmission\",\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0--------------------------------------------------------------------------------------------------------\n",
      " features | (322,[0,5,7,8,12,13,108,144,314,315,316,317,318,320,321],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1512398... \n",
      " label    | 0                                                                                                    \n",
      "-RECORD 1--------------------------------------------------------------------------------------------------------\n",
      " features | (322,[0,5,7,8,12,17,103,144,314,315,316,317,318,320,321],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1512398... \n",
      " label    | 0                                                                                                    \n",
      "-RECORD 2--------------------------------------------------------------------------------------------------------\n",
      " features | (322,[1,5,7,8,12,13,102,144,314,315,316,318,320,321],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1512398.25,... \n",
      " label    | 0                                                                                                    \n",
      "-RECORD 3--------------------------------------------------------------------------------------------------------\n",
      " features | (322,[1,5,7,8,12,13,102,144,314,315,316,318,320,321],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1512398.25,... \n",
      " label    | 0                                                                                                    \n",
      "-RECORD 4--------------------------------------------------------------------------------------------------------\n",
      " features | (322,[0,5,7,8,12,13,102,157,314,315,316,317,318,319,320,321],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,151... \n",
      " label    | 0                                                                                                    \n",
      "-RECORD 5--------------------------------------------------------------------------------------------------------\n",
      " features | (322,[0,5,7,8,12,16,106,144,314,315,316,317,318,320,321],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1512398... \n",
      " label    | 0                                                                                                    \n",
      "-RECORD 6--------------------------------------------------------------------------------------------------------\n",
      " features | (322,[0,5,7,8,12,18,106,178,314,315,316,317,318,319,320,321],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,151... \n",
      " label    | 0                                                                                                    \n",
      "-RECORD 7--------------------------------------------------------------------------------------------------------\n",
      " features | (322,[0,5,7,8,12,13,102,157,314,315,316,317,318,319,320,321],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,151... \n",
      " label    | 0                                                                                                    \n",
      "-RECORD 8--------------------------------------------------------------------------------------------------------\n",
      " features | (322,[1,4,5,8,13,102,144,314,315,316,318,320,321],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1472472.47,10198.6... \n",
      " label    | 0                                                                                                    \n",
      "-RECORD 9--------------------------------------------------------------------------------------------------------\n",
      " features | (322,[0,4,5,8,17,103,144,314,315,316,317,318,320,321],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1472472.47,101... \n",
      " label    | 0                                                                                                    \n",
      "-RECORD 10-------------------------------------------------------------------------------------------------------\n",
      " features | (322,[0,4,5,8,32,106,144,314,315,316,317,318,320,321],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1472472.47,101... \n",
      " label    | 0                                                                                                    \n",
      "-RECORD 11-------------------------------------------------------------------------------------------------------\n",
      " features | (322,[1,4,5,8,13,102,144,314,315,316,318,320,321],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1472472.47,10198.6... \n",
      " label    | 1                                                                                                    \n",
      "-RECORD 12-------------------------------------------------------------------------------------------------------\n",
      " features | (322,[2,4,5,8,37,107,144,314,315,316,318,320,321],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1472472.47,10198.6... \n",
      " label    | 0                                                                                                    \n",
      "-RECORD 13-------------------------------------------------------------------------------------------------------\n",
      " features | (322,[3,4,5,8,37,116,144,314,315,316,317,318,320,321],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1472472.47,101... \n",
      " label    | 0                                                                                                    \n",
      "-RECORD 14-------------------------------------------------------------------------------------------------------\n",
      " features | (322,[2,4,5,8,13,107,191,314,315,316,317,318,319,320,321],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1472472.47... \n",
      " label    | 0                                                                                                    \n",
      "-RECORD 15-------------------------------------------------------------------------------------------------------\n",
      " features | (322,[0,4,5,8,13,102,157,314,315,316,317,318,319,320,321],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1472472.47... \n",
      " label    | 0                                                                                                    \n",
      "-RECORD 16-------------------------------------------------------------------------------------------------------\n",
      " features | (322,[0,4,5,8,19,106,144,314,315,316,317,318,320,321],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1472472.47,101... \n",
      " label    | 0                                                                                                    \n",
      "-RECORD 17-------------------------------------------------------------------------------------------------------\n",
      " features | (322,[0,4,5,8,20,103,144,314,315,316,317,318,320,321],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1472472.47,101... \n",
      " label    | 0                                                                                                    \n",
      "-RECORD 18-------------------------------------------------------------------------------------------------------\n",
      " features | (322,[0,4,5,8,20,103,199,314,315,316,317,318,319,320,321],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1472472.47... \n",
      " label    | 1                                                                                                    \n",
      "-RECORD 19-------------------------------------------------------------------------------------------------------\n",
      " features | (322,[0,4,5,8,20,103,199,314,315,316,317,318,319,320,321],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1472472.47... \n",
      " label    | 0                                                                                                    \n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "training_data.show(vertical=True, truncate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change the role name - Took the role from Notebook instance\n",
    "iam_role = \"arn:aws:iam::176385768664:role/readmission-blog-GlueServiceRole-1V8JSLNMH01MA\"\n",
    "\n",
    "#from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "from sagemaker_pyspark import SageMakerEstimator\n",
    "from sagemaker_pyspark.transformation.deserializers import KMeansProtobufResponseRowDeserializer\n",
    "from sagemaker_pyspark.transformation.serializers import ProtobufRequestRowSerializer\n",
    "from sagemaker_pyspark import IAMRole\n",
    "from sagemaker_pyspark import RandomNamePolicyFactory\n",
    "from sagemaker_pyspark import EndpointCreationPolicy\n",
    "\n",
    "# Create an Estimator from scratch\n",
    "estimator = SageMakerEstimator(\n",
    "    trainingImage = 246618743249.dkr.ecr.us-west-2.amazonaws.com, # Training image \n",
    "    modelImage = get_image_uri(region, 'xgboost'), # Model image\n",
    "    sagemakerRole = IAMRole(role),\n",
    "    trainingInstanceType = \"ml.m4.xlarge\",\n",
    "    trainingInstanceCount = 1,\n",
    "    endpointInstanceType = \"ml.t2.medium\",\n",
    "    endpointInitialInstanceCount = 1,\n",
    "    trainingSparkDataFormat = \"sagemaker\",\n",
    "    namePolicyFactory = RandomNamePolicyFactory(\"sparksm-4-\"),\n",
    "    endpointCreationPolicy = EndpointCreationPolicy.CREATE_ON_TRANSFORM\n",
    "    )\n",
    "\n",
    "\n",
    "#xgboost_estimator.setObjective('multi:softmax')\n",
    "#xgboost_estimator.setNumRound(25)\n",
    "#xgboost_estimator.setNumClasses(10)\n",
    "\n",
    "#xgboost_model = xgboost_estimator.fit(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.getConf().getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "No module named 'sagemaker'\n",
      "Traceback (most recent call last):\n",
      "ModuleNotFoundError: No module named 'sagemaker'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method JavaWrapper.__del__ of <sagemaker_pyspark.wrapper.ScalaMap object at 0x7f3ef9294c88>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/yarn/usercache/livy/appcache/application_1581910656831_0027/container_1581910656831_0027_01_000001/pyspark.zip/pyspark/ml/wrapper.py\", line 40, in __del__\n",
      "AttributeError: 'ScalaMap' object has no attribute '_java_obj'\n",
      "Exception ignored in: <bound method JavaWrapper.__del__ of <sagemaker_pyspark.wrapper.ScalaMap object at 0x7f3ef9294c88>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/yarn/usercache/livy/appcache/application_1581910656831_0027/container_1581910656831_0027_01_000001/pyspark.zip/pyspark/ml/wrapper.py\", line 40, in __del__\n",
      "AttributeError: 'ScalaMap' object has no attribute '_java_obj'\n",
      "Exception ignored in: <bound method JavaWrapper.__del__ of <sagemaker_pyspark.wrapper.Option object at 0x7f3ef93b30f0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/yarn/usercache/livy/appcache/application_1581910656831_0027/container_1581910656831_0027_01_000001/pyspark.zip/pyspark/ml/wrapper.py\", line 40, in __del__\n",
      "AttributeError: 'Option' object has no attribute '_java_obj'\n",
      "Exception ignored in: <bound method JavaWrapper.__del__ of <sagemaker_pyspark.wrapper.Option object at 0x7f3ef85560b8>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/yarn/usercache/livy/appcache/application_1581910656831_0027/container_1581910656831_0027_01_000001/pyspark.zip/pyspark/ml/wrapper.py\", line 40, in __del__\n",
      "AttributeError: 'Option' object has no attribute '_java_obj'\n",
      "Exception ignored in: <bound method JavaWrapper.__del__ of <sagemaker_pyspark.wrapper.Option object at 0x7f3ef8556240>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/yarn/usercache/livy/appcache/application_1581910656831_0027/container_1581910656831_0027_01_000001/pyspark.zip/pyspark/ml/wrapper.py\", line 40, in __del__\n",
      "AttributeError: 'Option' object has no attribute '_java_obj'\n",
      "Exception ignored in: <bound method JavaWrapper.__del__ of <sagemaker_pyspark.wrapper.Option object at 0x7f3ef926cfd0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/yarn/usercache/livy/appcache/application_1581910656831_0027/container_1581910656831_0027_01_000001/pyspark.zip/pyspark/ml/wrapper.py\", line 40, in __del__\n",
      "AttributeError: 'Option' object has no attribute '_java_obj'\n",
      "Exception ignored in: <bound method JavaWrapper.__del__ of <sagemaker_pyspark.wrapper.Option object at 0x7f3ef928c780>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/yarn/usercache/livy/appcache/application_1581910656831_0027/container_1581910656831_0027_01_000001/pyspark.zip/pyspark/ml/wrapper.py\", line 40, in __del__\n",
      "AttributeError: 'Option' object has no attribute '_java_obj'"
     ]
    }
   ],
   "source": [
    "import sagemaker_pyspark\n",
    "from sagemaker_pyspark import IAMRole, EndpointCreationPolicy\n",
    "from sagemaker_pyspark.algorithms import XGBoostSageMakerEstimator\n",
    "from sagemaker_pyspark.transformation.serializers.serializers import UnlabeledCSVRequestRowSerializer\n",
    "\n",
    "iam_role = \"arn:aws:iam::176385768664:role/readmission-blog-SGNotebookRole-1JDNGNM2AMAA5\"\n",
    "\n",
    "xgboost_estimator = XGBoostSageMakerEstimator(\n",
    "    trainingInstanceType=\"ml.m4.xlarge\",\n",
    "    trainingInstanceCount=1,\n",
    "    endpointInstanceType=\"ml.m4.xlarge\",\n",
    "    endpointInitialInstanceCount=1,\n",
    "    sagemakerRole=IAMRole(iam_role))\n",
    "\n",
    "#xgboost_estimator.setNumRound(25) # Set number of trees to use\n",
    "#xgboost_estimator.setNumClasses(2) # data contains \n",
    "#xgboost_estimator.setObjective('binary:logistic') # Set XGBoost objective to multi-class classification w/ SoftMax\n",
    "\n",
    "#xgboost_model = xgboost_estimator.fit(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
